{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VS1VjIlaizUp",
    "outputId": "2689620b-1ed2-471b-a739-2019eeeeee59"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-FrTlbhi-3f",
    "outputId": "3548697f-45f9-4052-e7c3-cdc5b978f802"
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dszj_shgjBv9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlf25Y2pjHmA"
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hsoz_E9LjJja"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPwQx9aZjPrb",
    "outputId": "c167a87c-c45d-40aa-9959-2304c4a40f4a"
   },
   "outputs": [],
   "source": [
    "#!unzip \"/content/drive/MyDrive/Lavanya K/images.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smo6pm0dkiE7"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "id": "M4uukmr8lQnt",
    "outputId": "0b3002c4-7156-4438-a010-8a91ffe17eef"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Dataset/Dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pITrIi6GmZPZ",
    "outputId": "84733d15-8383-4204-9771-11a888c29cbb"
   },
   "outputs": [],
   "source": [
    "features = [\"SEASON\", \"SUBBASIN\", \"ISO_TIME\", \"WMO_WIND\"]\n",
    "#features.append(\"WMO_PRES\")\n",
    "data = data[features]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Images to the Winddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BB0MTDtSnFcP",
    "outputId": "d0181d81-58f1-4d81-c627-c6c688c2990f"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date_series = data[\"ISO_TIME\"]\n",
    "datetime_series = pd.to_datetime(date_series, format=\"%d-%m-%Y %H:%M\")\n",
    "formatted_series = datetime_series.dt.strftime(\"%d%b%Y_%H%M\").str.upper()\n",
    "file_name = \"3DIMG_\" + formatted_series + \"_L1C_ASIA_MER_IR1_V01R00.jpg\"\n",
    "\n",
    "file_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "el41qmRdtu48"
   },
   "outputs": [],
   "source": [
    "data[\"IR1\"] = file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "sIClJfDXvJyb",
    "outputId": "f928937f-2a18-4f1a-c774-5e9788a7132f"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind column Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['WMO_WIND'] = data['WMO_WIND'].replace(' ', 0)\n",
    "data['WMO_WIND'] = pd.to_numeric(data['WMO_WIND'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlighting the clouds of the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_highlighting(cropped_image):\n",
    "    \n",
    "    img_array = np.array(cropped_image)\n",
    "\n",
    "    single_channel = img_array[:, :, 0]\n",
    "\n",
    "    ret1, thresh = cv2.threshold(single_channel, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    opening = clear_border(opening)\n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=10)\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    ret2, sure_fg = cv2.threshold(dist_transform, 0.5 * dist_transform.max(), 255, 0)\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    ret3, markers = cv2.connectedComponents(sure_fg)\n",
    "    markers = markers + 10\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    markers = cv2.watershed(img_array, markers)\n",
    "\n",
    "    img_array[markers == -1] = [255, 87, 51]\n",
    "    img2 = color.label2rgb(markers, bg_label=0)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img_array)\n",
    "    plt.axis('off')\n",
    "    plt.title('Watershed')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def image_highlighting_grabcut(cropped_image):\n",
    "    img_array = np.array(cropped_image)\n",
    "\n",
    "    # Initialize rectangle for GrabCut\n",
    "    h, w = img_array.shape[:2]\n",
    "    rect = (10, 10, w-20, h-20)\n",
    "\n",
    "    mask = np.zeros(img_array.shape[:2], dtype=np.uint8)\n",
    "    bgdModel = np.zeros((1, 65), dtype=np.float64)\n",
    "    fgdModel = np.zeros((1, 65), dtype=np.float64)\n",
    "\n",
    "    # Run GrabCut algorithm\n",
    "    cv2.grabCut(img_array, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "    # Create mask where sure foreground and likely foreground are identified\n",
    "    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "\n",
    "    # Apply mask to original image\n",
    "    img_array = img_array * mask2[:, :, np.newaxis]\n",
    "\n",
    "    # Highlight cyclone boundaries\n",
    "    img_array[np.where((img_array == [0, 0, 0]).all(axis=2))] = [255, 255, 255]\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img_array)\n",
    "    plt.axis('off')\n",
    "    plt.title('GrabCut')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import slic\n",
    "from skimage.graph import rag_mean_color\n",
    "from skimage.graph import cut_normalized\n",
    "\n",
    "def image_highlighting_superpixels(cropped_image):\n",
    "    img_array = np.array(cropped_image)\n",
    "\n",
    "    # Convert image to LAB color space\n",
    "    lab_image = cv2.cvtColor(img_array, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Perform superpixel segmentation\n",
    "    segments = slic(lab_image, n_segments=500, compactness=10, sigma=1)\n",
    "\n",
    "    # Create graph from superpixels\n",
    "    g = rag_mean_color(lab_image, segments)\n",
    "\n",
    "    # Perform graph cuts to extract foreground\n",
    "    labels = cut_normalized(segments, g)\n",
    "\n",
    "    # Highlight cyclone boundaries\n",
    "    img_array[labels == 0] = [0, 0, 0]\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img_array)\n",
    "    plt.axis('off')\n",
    "    plt.title('Superpixels')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import felzenszwalb\n",
    "\n",
    "def image_highlighting_felzenszwalb(cropped_image):\n",
    "    img_array = np.array(cropped_image)\n",
    "\n",
    "    # Convert image to RGB color space\n",
    "    rgb_image = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform Felzenszwalb's algorithm for segmentation\n",
    "    segments = felzenszwalb(rgb_image, scale=100, sigma=0.3, min_size=100)\n",
    "\n",
    "    # Highlight cyclone boundaries\n",
    "    img_array[segments == 0] = [255, 87, 51]\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img_array)\n",
    "    plt.axis('off')\n",
    "    plt.title('Felzenszwalb')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "def image_highlighting_resnet(cropped_image):\n",
    "    # Convert the image to a NumPy array\n",
    "    img_array = np.array(cropped_image)\n",
    "\n",
    "    # Ensure the image is in RGB format\n",
    "    if len(img_array.shape) == 2:  # Grayscale image\n",
    "        img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)\n",
    "    elif img_array.shape[2] == 4:  # RGBA image\n",
    "        img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "    # Resize the image to match the input size of ResNet-50\n",
    "    resized_image = cv2.resize(img_array, (224, 224))\n",
    "\n",
    "    # Preprocess the image for ResNet-50\n",
    "    preprocessed_image = preprocess_input(resized_image)\n",
    "\n",
    "    # Add batch dimension to the preprocessed image\n",
    "    preprocessed_image = np.expand_dims(preprocessed_image, axis=0)\n",
    "\n",
    "    # Load the ResNet-50 model\n",
    "    model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "    # Encode the image using ResNet-50\n",
    "    features = model.predict(preprocessed_image)\n",
    "\n",
    "    # Perform segmentation decoding and highlighting\n",
    "    # ... Add your segmentation decoding and highlighting code here ...\n",
    "    # Here's an example code snippet for highlighting the image using watershed segmentation:\n",
    "\n",
    "    single_channel = img_array[:, :, 0]\n",
    "\n",
    "    ret1, thresh = cv2.threshold(single_channel, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    opening = clear_border(opening)\n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=10)\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    ret2, sure_fg = cv2.threshold(dist_transform, 0.5 * dist_transform.max(), 255, 0)\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    ret3, markers = cv2.connectedComponents(sure_fg)\n",
    "    markers = markers + 10\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    markers = cv2.watershed(img_array, markers)\n",
    "\n",
    "    img_array[markers == -1] = [255, 87, 51]\n",
    "    img2 = color.label2rgb(markers, bg_label=0)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img2)\n",
    "    plt.axis('off')\n",
    "    plt.title('ResNet')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Return the highlighted image\n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "def image_segmentation_meanshift(cropped_image):\n",
    "    img_array = np.array(cropped_image)\n",
    "    \n",
    "    # Convert the image to the Lab color space\n",
    "    img_lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2Lab)\n",
    "\n",
    "    # Reshape the image to 2D array\n",
    "    img_2d = img_lab.reshape((-1, 3))\n",
    "\n",
    "    # Estimate the bandwidth for Mean Shift\n",
    "    bandwidth = estimate_bandwidth(img_2d, quantile=0.2, n_samples=500)\n",
    "\n",
    "    # Perform Mean Shift clustering\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    ms.fit(img_2d)\n",
    "\n",
    "    # Get the labels assigned to each pixel\n",
    "    labels = ms.labels_\n",
    "\n",
    "    # Reshape the labels to match the original image shape\n",
    "    labels_2d = labels.reshape(img_array.shape[:2])\n",
    "\n",
    "    img_array[labels_2d == -1] = [255, 87, 51]\n",
    "    # Convert the labels to RGB image\n",
    "    segmented_img = color.label2rgb(labels_2d, img_array, kind='avg', bg_label=0)\n",
    "\n",
    "    # Display the segmented image\n",
    "    plt.imshow(segmented_img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Mean Shift Segmentation')\n",
    "    plt.show()\n",
    "    \n",
    "    return segmented_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "def image_segmentation_slic(cropped_image):\n",
    "    img_array = np.array(cropped_image)\n",
    "\n",
    "    # Perform SLIC segmentation\n",
    "    segments = slic(img_array, n_segments=100, compactness=10)\n",
    "\n",
    "    # Create a mask for each segment\n",
    "    mask = np.zeros_like(img_array)\n",
    "\n",
    "    # Iterate over each segment and assign corresponding pixels to the mask\n",
    "    for segment_label in np.unique(segments):\n",
    "        mask[segments == segment_label] = img_array[segments == segment_label].mean(axis=0)\n",
    "\n",
    "    # Convert the mask to RGB image\n",
    "    segmented_img = label2rgb(segments, image=mask, bg_label=0)\n",
    "\n",
    "    # Display the segmented image\n",
    "    plt.imshow(segmented_img)\n",
    "    plt.axis('off')\n",
    "    plt.title('SLIC Segmentation')\n",
    "    plt.show()\n",
    "\n",
    "    return segmented_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def image_segmentation_kmeans(cropped_image):\n",
    "    img_array = np.array(cropped_image)\n",
    "\n",
    "    # Flatten the image to a 2D array of pixels\n",
    "    pixels = img_array.reshape(-1, 3)\n",
    "\n",
    "    # Perform K-Means clustering\n",
    "    kmeans = KMeans(n_clusters=5, random_state=0)\n",
    "    labels = kmeans.fit_predict(pixels)\n",
    "\n",
    "    # Assign cluster centers as the new pixel values\n",
    "    segmented_img = kmeans.cluster_centers_[labels].reshape(img_array.shape)\n",
    "\n",
    "    # Convert the segmented image to uint8 datatype\n",
    "    segmented_img = segmented_img.astype(np.uint8)\n",
    "\n",
    "    # Display the segmented image\n",
    "    plt.imshow(segmented_img)\n",
    "    plt.axis('off')\n",
    "    plt.title('K-Means Segmentation')\n",
    "    plt.show()\n",
    "\n",
    "    return segmented_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def image_segmentation_dbscan(cropped_image):\n",
    "    img_array = np.array(cropped_image)\n",
    "\n",
    "    # Flatten the image to a 2D array of pixels\n",
    "    pixels = img_array.reshape(-1, 3)\n",
    "\n",
    "    # Perform DBSCAN clustering\n",
    "    dbscan = DBSCAN(eps=20, min_samples=100)\n",
    "    labels = dbscan.fit_predict(pixels)\n",
    "\n",
    "    # Get the number of clusters (excluding noise)\n",
    "    num_clusters = len(np.unique(labels)) - 1\n",
    "\n",
    "    # Create a mask for the segmented regions\n",
    "    segmented_mask = labels.reshape(img_array.shape[:2])\n",
    "\n",
    "    # Generate random colors for each cluster\n",
    "    cluster_colors = np.random.randint(0, 256, (num_clusters, 3))\n",
    "\n",
    "    # Apply colors to the segmented regions\n",
    "    segmented_img = np.zeros_like(img_array)\n",
    "    for cluster_id in range(1, num_clusters + 1):\n",
    "        segmented_img[segmented_mask == cluster_id] = cluster_colors[cluster_id - 1]\n",
    "\n",
    "    # Display the segmented image\n",
    "    plt.imshow(segmented_img)\n",
    "    plt.axis('off')\n",
    "    plt.title('DBSCAN Segmentation')\n",
    "    plt.show()\n",
    "\n",
    "    return segmented_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "def image_segmentation_spectral(cropped_image):\n",
    "    img_array = np.array(cropped_image)\n",
    "\n",
    "    # Flatten the image to a 2D array of pixels\n",
    "    pixels = img_array.reshape(-1, 3)\n",
    "\n",
    "    # Perform Spectral Clustering\n",
    "    spectral_clustering = SpectralClustering(n_clusters=5, affinity='nearest_neighbors', n_neighbors=10)\n",
    "    labels = spectral_clustering.fit_predict(pixels)\n",
    "\n",
    "    # Get the number of clusters\n",
    "    num_clusters = len(np.unique(labels))\n",
    "\n",
    "    # Create a mask for the segmented regions\n",
    "    segmented_mask = labels.reshape(img_array.shape[:2])\n",
    "\n",
    "    # Generate random colors for each cluster\n",
    "    cluster_colors = np.random.randint(0, 256, (num_clusters, 3))\n",
    "\n",
    "    # Apply colors to the segmented regions\n",
    "    segmented_img = np.zeros_like(img_array)\n",
    "    for cluster_id in range(num_clusters):\n",
    "        segmented_img[segmented_mask == cluster_id] = cluster_colors[cluster_id]\n",
    "\n",
    "    # Display the segmented image\n",
    "    plt.imshow(segmented_img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Spectral Clustering Segmentation')\n",
    "    plt.show()\n",
    "\n",
    "    return segmented_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def image_segmentation_canny(cropped_image):\n",
    "    img_array = np.array(cropped_image)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Apply Canny Edge Detection\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "    # Create a mask by thresholding the edges\n",
    "    mask = edges > 0\n",
    "\n",
    "    # Apply the mask to the original image to extract the edges\n",
    "    segmented_img = np.zeros_like(img_array)\n",
    "    segmented_img[mask] = [255, 0, 0]  # Highlight the edges in red\n",
    "\n",
    "    # Display the segmented image\n",
    "    plt.imshow(segmented_img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Canny Edge Detection Segmentation')\n",
    "    plt.show()\n",
    "\n",
    "    return segmented_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import active_contour\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "def image_segmentation_snakes(img):\n",
    "    # Convert the image to grayscale\n",
    "    img_gray = rgb2gray(img)\n",
    "\n",
    "    # Initialize the snake contour\n",
    "    snake_init = np.array([[10, 10], [10, 100], [100, 100], [100, 10]])\n",
    "\n",
    "    # Run the active contours (snakes) algorithm\n",
    "    snake = active_contour(img_gray, snake_init, alpha=0.1, beta=0.1, gamma=0.01)\n",
    "\n",
    "    # Create a blank image for visualization\n",
    "    visualization = np.zeros_like(img)\n",
    "\n",
    "    # Draw the snake contour on the visualization image\n",
    "    cv2.polylines(visualization, [np.int32(snake)], isClosed=True, color=(255, 0, 0), thickness=2)\n",
    "\n",
    "    # Display the segmented image\n",
    "    plt.imshow(visualization)\n",
    "    plt.axis('off')\n",
    "    plt.title('Active Contours Segmentation')\n",
    "    plt.show()\n",
    "\n",
    "    return visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.segmentation import chan_vese\n",
    "\n",
    "def image_segmentation_level_sets(cropped_image):\n",
    "    # Convert the image to grayscale\n",
    "    img_gray = rgb2gray(cropped_image)\n",
    "\n",
    "    # Apply the Chan-Vese level set algorithm\n",
    "    mask = chan_vese(img_gray, mu=0.25, lambda1=1, lambda2=1, tol=1e-3)\n",
    "\n",
    "    # Create a mask overlay on the original image\n",
    "    segmented_image = np.zeros_like(cropped_image)\n",
    "    segmented_image[mask] = [255, 255, 255]  # Highlight the segmented regions in red\n",
    "\n",
    "    # Display the segmented image\n",
    "    plt.imshow(segmented_image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Level Sets Segmentation')\n",
    "    plt.show()\n",
    "\n",
    "    return segmented_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Pre-processed images locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_image(img_array, filename):\n",
    "    output_dir = 'Dataset/pre-processing/Level-Sets-Segmentation/'\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    processed_image = Image.fromarray(img_array)\n",
    "    processed_image.save(output_path)\n",
    "    print(f\"Processed image saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping the required section of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "hfZk3V-6Gyl0",
    "outputId": "48e42ff7-e9da-41f2-d015-456c8affd5c4"
   },
   "outputs": [],
   "source": [
    "def image_crop(image, filename):\n",
    "    if int(filename[11:15]) <= 2020 or 'MAY2021' in filename or 'SEP2021' in filename:\n",
    "        crop_coords = (150, 300, 600, 700)\n",
    "    else:\n",
    "        crop_coords = (300, 600, 1200, 1300)\n",
    "    cropped_image = image.crop(crop_coords)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Original Image')\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "5QWDSzrv-MaS",
    "outputId": "2797f569-e3ed-4886-816d-f4e69e74fb40",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import color\n",
    "\n",
    "image_folder_path = 'Dataset/images/'\n",
    "\n",
    "row = data.iloc[2]\n",
    "\n",
    "filename = row['IR1']\n",
    "image_path = image_folder_path + filename\n",
    "image = Image.open(image_path)\n",
    "cropped_image = image_crop(image, filename)\n",
    "highlighted_image = image_highlighting(cropped_image)\n",
    "highlighted_image = image_highlighting_grabcut(cropped_image)\n",
    "highlighted_image = image_highlighting_superpixels(cropped_image)\n",
    "highlighted_image = image_highlighting_felzenszwalb(cropped_image)\n",
    "highlighted_image = image_highlighting_resnet(cropped_image)\n",
    "highlighted_image = image_segmentation_meanshift(cropped_image)\n",
    "highlighted_image = image_segmentation_slic(cropped_image)\n",
    "highlighted_image = image_segmentation_kmeans(cropped_image)\n",
    "#highlighted_image = image_segmentation_dbscan(cropped_image)\n",
    "#highlighted_image = image_segmentation_spectral(cropped_image)\n",
    "highlighted_image = image_segmentation_canny(cropped_image)\n",
    "highlighted_image = image_segmentation_snakes(cropped_image)\n",
    "highlighted_image = image_segmentation_level_sets(cropped_image)\n",
    "#save_processed_image(highlighted_image, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Pre-processed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzH9yxvkyFp5",
    "outputId": "7723043e-38a9-488b-94ca-73ab7cac4a80",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "image_folder_path = 'Dataset/images/'\n",
    "\n",
    "image_counter = 0\n",
    "image_not_counter = 0\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    filename = row['IR1']\n",
    "    \n",
    "    image_path = image_folder_path + filename\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        cropped_image = image_crop(image, filename)\n",
    "        highlighted_image = image_segmentation_level_sets(cropped_image)\n",
    "        save_processed_image(highlighted_image, filename)\n",
    "        image_counter += 1\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        image_not_counter += 1\n",
    "    \n",
    "print(image_counter)\n",
    "print(image_not_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_image(img_array, filename):\n",
    "    output_dir = 'Dataset/pre-processing/K-Means-Segmentation/'\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    processed_image = Image.fromarray(img_array)\n",
    "    processed_image.save(output_path)\n",
    "    print(f\"Processed image saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "image_folder_path = 'Dataset/images/'\n",
    "\n",
    "image_counter = 0\n",
    "image_not_counter = 0\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    filename = row['IR1']\n",
    "    \n",
    "    image_path = image_folder_path + filename\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        cropped_image = image_crop(image, filename)\n",
    "        highlighted_image = image_segmentation_kmeans(cropped_image)\n",
    "        save_processed_image(highlighted_image, filename)\n",
    "        image_counter += 1\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        image_not_counter += 1\n",
    "    \n",
    "print(image_counter)\n",
    "print(image_not_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_image(img_array, filename):\n",
    "    output_dir = 'Dataset/pre-processing/SLIC-Segmentation/'\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    processed_image = Image.fromarray(img_array)\n",
    "    processed_image.save(output_path)\n",
    "    print(f\"Processed image saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "image_folder_path = 'Dataset/images/'\n",
    "\n",
    "image_counter = 0\n",
    "image_not_counter = 0\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    filename = row['IR1']\n",
    "    \n",
    "    image_path = image_folder_path + filename\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        cropped_image = image_crop(image, filename)\n",
    "        highlighted_image = image_segmentation_slic(cropped_image)\n",
    "        save_processed_image(highlighted_image, filename)\n",
    "        image_counter += 1\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        image_not_counter += 1\n",
    "    \n",
    "print(image_counter)\n",
    "print(image_not_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_image(img_array, filename):\n",
    "    output_dir = 'Dataset/pre-processing/Mean-Shift-Segmentation/'\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    processed_image = Image.fromarray(img_array)\n",
    "    processed_image.save(output_path)\n",
    "    print(f\"Processed image saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "image_folder_path = 'Dataset/images/'\n",
    "\n",
    "image_counter = 0\n",
    "image_not_counter = 0\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    filename = row['IR1']\n",
    "    \n",
    "    image_path = image_folder_path + filename\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        cropped_image = image_crop(image, filename)\n",
    "        highlighted_image = image_segmentation_meanshift(cropped_image)\n",
    "        save_processed_image(highlighted_image, filename)\n",
    "        image_counter += 1\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        image_not_counter += 1\n",
    "    \n",
    "print(image_counter)\n",
    "print(image_not_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_image(img_array, filename):\n",
    "    output_dir = 'Dataset/pre-processing/ResNet/'\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    processed_image = Image.fromarray(img_array)\n",
    "    processed_image.save(output_path)\n",
    "    print(f\"Processed image saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "image_folder_path = 'Dataset/images/'\n",
    "\n",
    "image_counter = 0\n",
    "image_not_counter = 0\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    filename = row['IR1']\n",
    "    \n",
    "    image_path = image_folder_path + filename\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        cropped_image = image_crop(image, filename)\n",
    "        highlighted_image = image_highlighting_resnet(cropped_image)\n",
    "        save_processed_image(highlighted_image, filename)\n",
    "        image_counter += 1\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        image_not_counter += 1\n",
    "    \n",
    "print(image_counter)\n",
    "print(image_not_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IOkX7w7Li0a"
   },
   "source": [
    "## Loading the pre-processed images into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    try:\n",
    "        image = tf.io.read_file('Dataset/processed_images/' + image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, (256, 256))\n",
    "        image = image / 255.0\n",
    "        return image, image_path\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None, image_path\n",
    "\n",
    "data['image'], data['IR1'] = zip(*data['IR1'].apply(load_and_preprocess_image))\n",
    "\n",
    "data = data.dropna(subset=['image'])\n",
    "\n",
    "images = tf.stack(list(data['image'].values))\n",
    "labels = data['WMO_WIND'].values.astype(float)\n",
    "\n",
    "filenames = data['IR1'].values\n",
    "\n",
    "dataset_display = tf.data.Dataset.from_tensor_slices((images, labels, filenames))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 10\n",
    "image_samples = dataset_display.take(num_images)\n",
    "\n",
    "for image, label, image_filename in image_samples:\n",
    "    wind_value = label.numpy() \n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Wind Value: {wind_value}\\nFilename: {image_filename}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(train_size).batch(batch_size).prefetch(1)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "k = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "for train_index, val_index in skf.split(images, labels):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((images[train_index], labels[train_index]))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((images[val_index], labels[val_index]))\n",
    "    \n",
    "    train_dataset = train_dataset.shuffle(1000).batch(32)\n",
    "    val_dataset = val_dataset.batch(32)\n",
    "    \n",
    "    data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    "    )\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(train_dataset, epochs=20, verbose=0)\n",
    "    \n",
    "    train_loss, train_accuracy = model.evaluate(train_dataset, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(val_dataset, verbose=0)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "print('Average training loss:', np.mean(train_losses))\n",
    "print('Average training accuracy:', np.mean(train_accuracies))\n",
    "print('Training losses:', train_losses)\n",
    "print('Training accuracies:', train_accuracies)\n",
    "print('Average validation loss:', np.mean(val_losses))\n",
    "print('Average validation accuracy:', np.mean(val_accuracies))\n",
    "print('Validation losses:', val_losses)\n",
    "print('Validation accuracies:', val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level Set Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Dataset/Dataset.csv\")\n",
    "data.head()\n",
    "\n",
    "features = [\"SEASON\", \"SUBBASIN\", \"ISO_TIME\", \"WMO_WIND\"]\n",
    "#features.append(\"WMO_PRES\")\n",
    "data = data[features]\n",
    "data.head()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "date_series = data[\"ISO_TIME\"]\n",
    "datetime_series = pd.to_datetime(date_series, format=\"%d-%m-%Y %H:%M\")\n",
    "formatted_series = datetime_series.dt.strftime(\"%d%b%Y_%H%M\").str.upper()\n",
    "file_name = \"3DIMG_\" + formatted_series + \"_L1C_ASIA_MER_IR1_V01R00.jpg\"\n",
    "\n",
    "file_name.head()\n",
    "\n",
    "data[\"IR1\"] = file_name\n",
    "\n",
    "data.head()\n",
    "\n",
    "data['WMO_WIND'] = data['WMO_WIND'].replace(' ', 0)\n",
    "data['WMO_WIND'] = pd.to_numeric(data['WMO_WIND'], errors='coerce')\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    try:\n",
    "        image = tf.io.read_file('Dataset/pre-processing/Level-Sets-Segmentation/' + image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, (256, 256))\n",
    "        image = image / 255.0\n",
    "        return image, image_path\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None, image_path\n",
    "\n",
    "data['image'], data['IR1'] = zip(*data['IR1'].apply(load_and_preprocess_image))\n",
    "\n",
    "data = data.dropna(subset=['image'])\n",
    "\n",
    "images = tf.stack(list(data['image'].values))\n",
    "labels = data['WMO_WIND'].values.astype(float)\n",
    "\n",
    "filenames = data['IR1'].values\n",
    "\n",
    "dataset_display = tf.data.Dataset.from_tensor_slices((images, labels, filenames))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 10\n",
    "image_samples = dataset_display.take(num_images)\n",
    "\n",
    "for image, label, image_filename in image_samples:\n",
    "    wind_value = label.numpy() \n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Wind Value: {wind_value}\\nFilename: {image_filename}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(train_size).batch(batch_size).prefetch(1)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "k = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "for train_index, val_index in skf.split(images, labels):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((images[train_index], labels[train_index]))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((images[val_index], labels[val_index]))\n",
    "    \n",
    "    train_dataset = train_dataset.shuffle(1000).batch(32)\n",
    "    val_dataset = val_dataset.batch(32)\n",
    "    \n",
    "    data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    "    )\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(train_dataset, epochs=20, verbose=0)\n",
    "    \n",
    "    train_loss, train_accuracy = model.evaluate(train_dataset, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(val_dataset, verbose=0)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "print('Average training loss:', np.mean(train_losses))\n",
    "print('Average training accuracy:', np.mean(train_accuracies))\n",
    "print('Training losses:', train_losses)\n",
    "print('Training accuracies:', train_accuracies)\n",
    "print('Average validation loss:', np.mean(val_losses))\n",
    "print('Average validation accuracy:', np.mean(val_accuracies))\n",
    "print('Validation losses:', val_losses)\n",
    "print('Validation accuracies:', val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Dataset/Dataset.csv\")\n",
    "data.head()\n",
    "\n",
    "features = [\"SEASON\", \"SUBBASIN\", \"ISO_TIME\", \"WMO_WIND\"]\n",
    "#features.append(\"WMO_PRES\")\n",
    "data = data[features]\n",
    "data.head()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "date_series = data[\"ISO_TIME\"]\n",
    "datetime_series = pd.to_datetime(date_series, format=\"%d-%m-%Y %H:%M\")\n",
    "formatted_series = datetime_series.dt.strftime(\"%d%b%Y_%H%M\").str.upper()\n",
    "file_name = \"3DIMG_\" + formatted_series + \"_L1C_ASIA_MER_IR1_V01R00.jpg\"\n",
    "\n",
    "file_name.head()\n",
    "\n",
    "data[\"IR1\"] = file_name\n",
    "\n",
    "data.head()\n",
    "\n",
    "data['WMO_WIND'] = data['WMO_WIND'].replace(' ', 0)\n",
    "data['WMO_WIND'] = pd.to_numeric(data['WMO_WIND'], errors='coerce')\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    try:\n",
    "        image = tf.io.read_file('Dataset/pre-processing/K-Means-Segmentation/' + image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, (256, 256))\n",
    "        image = image / 255.0\n",
    "        return image, image_path\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None, image_path\n",
    "\n",
    "data['image'], data['IR1'] = zip(*data['IR1'].apply(load_and_preprocess_image))\n",
    "\n",
    "data = data.dropna(subset=['image'])\n",
    "\n",
    "images = tf.stack(list(data['image'].values))\n",
    "labels = data['WMO_WIND'].values.astype(float)\n",
    "\n",
    "filenames = data['IR1'].values\n",
    "\n",
    "dataset_display = tf.data.Dataset.from_tensor_slices((images, labels, filenames))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 10\n",
    "image_samples = dataset_display.take(num_images)\n",
    "\n",
    "for image, label, image_filename in image_samples:\n",
    "    wind_value = label.numpy() \n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Wind Value: {wind_value}\\nFilename: {image_filename}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(train_size).batch(batch_size).prefetch(1)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "k = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "for train_index, val_index in skf.split(images, labels):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((images[train_index], labels[train_index]))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((images[val_index], labels[val_index]))\n",
    "    \n",
    "    train_dataset = train_dataset.shuffle(1000).batch(32)\n",
    "    val_dataset = val_dataset.batch(32)\n",
    "    \n",
    "    data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    "    )\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(train_dataset, epochs=20, verbose=0)\n",
    "    \n",
    "    train_loss, train_accuracy = model.evaluate(train_dataset, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(val_dataset, verbose=0)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "print('Average training loss:', np.mean(train_losses))\n",
    "print('Average training accuracy:', np.mean(train_accuracies))\n",
    "print('Training losses:', train_losses)\n",
    "print('Training accuracies:', train_accuracies)\n",
    "print('Average validation loss:', np.mean(val_losses))\n",
    "print('Average validation accuracy:', np.mean(val_accuracies))\n",
    "print('Validation losses:', val_losses)\n",
    "print('Validation accuracies:', val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Shift Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Dataset/Dataset.csv\")\n",
    "data.head()\n",
    "\n",
    "features = [\"SEASON\", \"SUBBASIN\", \"ISO_TIME\", \"WMO_WIND\"]\n",
    "#features.append(\"WMO_PRES\")\n",
    "data = data[features]\n",
    "data.head()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "date_series = data[\"ISO_TIME\"]\n",
    "datetime_series = pd.to_datetime(date_series, format=\"%d-%m-%Y %H:%M\")\n",
    "formatted_series = datetime_series.dt.strftime(\"%d%b%Y_%H%M\").str.upper()\n",
    "file_name = \"3DIMG_\" + formatted_series + \"_L1C_ASIA_MER_IR1_V01R00.jpg\"\n",
    "\n",
    "file_name.head()\n",
    "\n",
    "data[\"IR1\"] = file_name\n",
    "\n",
    "data.head()\n",
    "\n",
    "data['WMO_WIND'] = data['WMO_WIND'].replace(' ', 0)\n",
    "data['WMO_WIND'] = pd.to_numeric(data['WMO_WIND'], errors='coerce')\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    try:\n",
    "        image = tf.io.read_file('Dataset/pre-processing/Mean-Shift-Segmentation/' + image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, (256, 256))\n",
    "        image = image / 255.0\n",
    "        return image, image_path\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None, image_path\n",
    "\n",
    "data['image'], data['IR1'] = zip(*data['IR1'].apply(load_and_preprocess_image))\n",
    "\n",
    "data = data.dropna(subset=['image'])\n",
    "\n",
    "images = tf.stack(list(data['image'].values))\n",
    "labels = data['WMO_WIND'].values.astype(float)\n",
    "\n",
    "filenames = data['IR1'].values\n",
    "\n",
    "dataset_display = tf.data.Dataset.from_tensor_slices((images, labels, filenames))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 10\n",
    "image_samples = dataset_display.take(num_images)\n",
    "\n",
    "for image, label, image_filename in image_samples:\n",
    "    wind_value = label.numpy() \n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Wind Value: {wind_value}\\nFilename: {image_filename}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(train_size).batch(batch_size).prefetch(1)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "k = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "for train_index, val_index in skf.split(images, labels):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((images[train_index], labels[train_index]))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((images[val_index], labels[val_index]))\n",
    "    \n",
    "    train_dataset = train_dataset.shuffle(1000).batch(32)\n",
    "    val_dataset = val_dataset.batch(32)\n",
    "    \n",
    "    data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    "    )\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(train_dataset, epochs=20, verbose=0)\n",
    "    \n",
    "    train_loss, train_accuracy = model.evaluate(train_dataset, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(val_dataset, verbose=0)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "print('Average training loss:', np.mean(train_losses))\n",
    "print('Average training accuracy:', np.mean(train_accuracies))\n",
    "print('Training losses:', train_losses)\n",
    "print('Training accuracies:', train_accuracies)\n",
    "print('Average validation loss:', np.mean(val_losses))\n",
    "print('Average validation accuracy:', np.mean(val_accuracies))\n",
    "print('Validation losses:', val_losses)\n",
    "print('Validation accuracies:', val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Dataset/Dataset.csv\")\n",
    "data.head()\n",
    "\n",
    "features = [\"SEASON\", \"SUBBASIN\", \"ISO_TIME\", \"WMO_WIND\"]\n",
    "#features.append(\"WMO_PRES\")\n",
    "data = data[features]\n",
    "data.head()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "date_series = data[\"ISO_TIME\"]\n",
    "datetime_series = pd.to_datetime(date_series, format=\"%d-%m-%Y %H:%M\")\n",
    "formatted_series = datetime_series.dt.strftime(\"%d%b%Y_%H%M\").str.upper()\n",
    "file_name = \"3DIMG_\" + formatted_series + \"_L1C_ASIA_MER_IR1_V01R00.jpg\"\n",
    "\n",
    "file_name.head()\n",
    "\n",
    "data[\"IR1\"] = file_name\n",
    "\n",
    "data.head()\n",
    "\n",
    "data['WMO_WIND'] = data['WMO_WIND'].replace(' ', 0)\n",
    "data['WMO_WIND'] = pd.to_numeric(data['WMO_WIND'], errors='coerce')\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    try:\n",
    "        image = tf.io.read_file('Dataset/pre-processing/ResNet/' + image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, (256, 256))\n",
    "        image = image / 255.0\n",
    "        return image, image_path\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None, image_path\n",
    "\n",
    "data['image'], data['IR1'] = zip(*data['IR1'].apply(load_and_preprocess_image))\n",
    "\n",
    "data = data.dropna(subset=['image'])\n",
    "\n",
    "images = tf.stack(list(data['image'].values))\n",
    "labels = data['WMO_WIND'].values.astype(float)\n",
    "\n",
    "filenames = data['IR1'].values\n",
    "\n",
    "dataset_display = tf.data.Dataset.from_tensor_slices((images, labels, filenames))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 10\n",
    "image_samples = dataset_display.take(num_images)\n",
    "\n",
    "for image, label, image_filename in image_samples:\n",
    "    wind_value = label.numpy() \n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Wind Value: {wind_value}\\nFilename: {image_filename}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(train_size).batch(batch_size).prefetch(1)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "k = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "for train_index, val_index in skf.split(images, labels):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((images[train_index], labels[train_index]))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((images[val_index], labels[val_index]))\n",
    "    \n",
    "    train_dataset = train_dataset.shuffle(1000).batch(32)\n",
    "    val_dataset = val_dataset.batch(32)\n",
    "    \n",
    "    data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    "    )\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(train_dataset, epochs=20, verbose=0)\n",
    "    \n",
    "    train_loss, train_accuracy = model.evaluate(train_dataset, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(val_dataset, verbose=0)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "print('Average training loss:', np.mean(train_losses))\n",
    "print('Average training accuracy:', np.mean(train_accuracies))\n",
    "print('Training losses:', train_losses)\n",
    "print('Training accuracies:', train_accuracies)\n",
    "print('Average validation loss:', np.mean(val_losses))\n",
    "print('Average validation accuracy:', np.mean(val_accuracies))\n",
    "print('Validation losses:', val_losses)\n",
    "print('Validation accuracies:', val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level Set Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Dataset/Dataset.csv\")\n",
    "data.head()\n",
    "\n",
    "features = [\"SEASON\", \"SUBBASIN\", \"ISO_TIME\", \"WMO_WIND\"]\n",
    "#features.append(\"WMO_PRES\")\n",
    "data = data[features]\n",
    "data.head()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "date_series = data[\"ISO_TIME\"]\n",
    "datetime_series = pd.to_datetime(date_series, format=\"%d-%m-%Y %H:%M\")\n",
    "formatted_series = datetime_series.dt.strftime(\"%d%b%Y_%H%M\").str.upper()\n",
    "file_name = \"3DIMG_\" + formatted_series + \"_L1C_ASIA_MER_IR1_V01R00.jpg\"\n",
    "\n",
    "file_name.head()\n",
    "\n",
    "data[\"IR1\"] = file_name\n",
    "\n",
    "data.head()\n",
    "\n",
    "data['WMO_WIND'] = data['WMO_WIND'].replace(' ', 0)\n",
    "data['WMO_WIND'] = pd.to_numeric(data['WMO_WIND'], errors='coerce')\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    try:\n",
    "        image = tf.io.read_file('Dataset/pre-processing/Level-Sets-Segmentation/' + image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, (256, 256))\n",
    "        image = image / 255.0\n",
    "        return image, image_path\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None, image_path\n",
    "\n",
    "data['image'], data['IR1'] = zip(*data['IR1'].apply(load_and_preprocess_image))\n",
    "\n",
    "data = data.dropna(subset=['image'])\n",
    "\n",
    "images = tf.stack(list(data['image'].values))\n",
    "labels = data['WMO_WIND'].values.astype(float)\n",
    "\n",
    "filenames = data['IR1'].values\n",
    "\n",
    "dataset_display = tf.data.Dataset.from_tensor_slices((images, labels, filenames))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 10\n",
    "image_samples = dataset_display.take(num_images)\n",
    "\n",
    "for image, label, image_filename in image_samples:\n",
    "    wind_value = label.numpy() \n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Wind Value: {wind_value}\\nFilename: {image_filename}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(train_size).batch(batch_size).prefetch(1)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "k = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "for train_index, val_index in skf.split(images, labels):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((images[train_index], labels[train_index]))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((images[val_index], labels[val_index]))\n",
    "    \n",
    "    train_dataset = train_dataset.shuffle(1000).batch(32)\n",
    "    val_dataset = val_dataset.batch(32)\n",
    "    \n",
    "    data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    "    )\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(train_dataset, epochs=20, verbose=0)\n",
    "    \n",
    "    train_loss, train_accuracy = model.evaluate(train_dataset, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(val_dataset, verbose=0)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "print('Average training loss:', np.mean(train_losses))\n",
    "print('Average training accuracy:', np.mean(train_accuracies))\n",
    "print('Training losses:', train_losses)\n",
    "print('Training accuracies:', train_accuracies)\n",
    "print('Average validation loss:', np.mean(val_losses))\n",
    "print('Average validation accuracy:', np.mean(val_accuracies))\n",
    "print('Validation losses:', val_losses)\n",
    "print('Validation accuracies:', val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Shift Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Dataset/Dataset.csv\")\n",
    "data.head()\n",
    "\n",
    "features = [\"SEASON\", \"SUBBASIN\", \"ISO_TIME\", \"WMO_WIND\"]\n",
    "#features.append(\"WMO_PRES\")\n",
    "data = data[features]\n",
    "data.head()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "date_series = data[\"ISO_TIME\"]\n",
    "datetime_series = pd.to_datetime(date_series, format=\"%d-%m-%Y %H:%M\")\n",
    "formatted_series = datetime_series.dt.strftime(\"%d%b%Y_%H%M\").str.upper()\n",
    "file_name = \"3DIMG_\" + formatted_series + \"_L1C_ASIA_MER_IR1_V01R00.jpg\"\n",
    "\n",
    "file_name.head()\n",
    "\n",
    "data[\"IR1\"] = file_name\n",
    "\n",
    "data.head()\n",
    "\n",
    "data['WMO_WIND'] = data['WMO_WIND'].replace(' ', 0)\n",
    "data['WMO_WIND'] = pd.to_numeric(data['WMO_WIND'], errors='coerce')\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    try:\n",
    "        image = tf.io.read_file('Dataset/pre-processing/Mean-Shift-Segmentation/' + image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, (256, 256))\n",
    "        image = image / 255.0\n",
    "        return image, image_path\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None, image_path\n",
    "\n",
    "data['image'], data['IR1'] = zip(*data['IR1'].apply(load_and_preprocess_image))\n",
    "\n",
    "data = data.dropna(subset=['image'])\n",
    "\n",
    "images = tf.stack(list(data['image'].values))\n",
    "labels = data['WMO_WIND'].values.astype(float)\n",
    "\n",
    "filenames = data['IR1'].values\n",
    "\n",
    "dataset_display = tf.data.Dataset.from_tensor_slices((images, labels, filenames))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 10\n",
    "image_samples = dataset_display.take(num_images)\n",
    "\n",
    "for image, label, image_filename in image_samples:\n",
    "    wind_value = label.numpy() \n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Wind Value: {wind_value}\\nFilename: {image_filename}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(train_size).batch(batch_size).prefetch(1)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "k = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "for train_index, val_index in skf.split(images, labels):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((images[train_index], labels[train_index]))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((images[val_index], labels[val_index]))\n",
    "    \n",
    "    train_dataset = train_dataset.shuffle(1000).batch(32)\n",
    "    val_dataset = val_dataset.batch(32)\n",
    "    \n",
    "    data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    "    )\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(train_dataset, epochs=20, verbose=0)\n",
    "    \n",
    "    train_loss, train_accuracy = model.evaluate(train_dataset, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(val_dataset, verbose=0)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "print('Average training loss:', np.mean(train_losses))\n",
    "print('Average training accuracy:', np.mean(train_accuracies))\n",
    "print('Training losses:', train_losses)\n",
    "print('Training accuracies:', train_accuracies)\n",
    "print('Average validation loss:', np.mean(val_losses))\n",
    "print('Average validation accuracy:', np.mean(val_accuracies))\n",
    "print('Validation losses:', val_losses)\n",
    "print('Validation accuracies:', val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Dataset/Dataset.csv\")\n",
    "data.head()\n",
    "\n",
    "features = [\"SEASON\", \"SUBBASIN\", \"ISO_TIME\", \"WMO_WIND\"]\n",
    "#features.append(\"WMO_PRES\")\n",
    "data = data[features]\n",
    "data.head()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "date_series = data[\"ISO_TIME\"]\n",
    "datetime_series = pd.to_datetime(date_series, format=\"%d-%m-%Y %H:%M\")\n",
    "formatted_series = datetime_series.dt.strftime(\"%d%b%Y_%H%M\").str.upper()\n",
    "file_name = \"3DIMG_\" + formatted_series + \"_L1C_ASIA_MER_IR1_V01R00.jpg\"\n",
    "\n",
    "file_name.head()\n",
    "\n",
    "data[\"IR1\"] = file_name\n",
    "\n",
    "data.head()\n",
    "\n",
    "data['WMO_WIND'] = data['WMO_WIND'].replace(' ', 0)\n",
    "data['WMO_WIND'] = pd.to_numeric(data['WMO_WIND'], errors='coerce')\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    try:\n",
    "        image = tf.io.read_file('Dataset/pre-processing/Level-Sets-Segmentation/' + image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, (256, 256))\n",
    "        image = image / 255.0\n",
    "        return image, image_path\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None, image_path\n",
    "\n",
    "data['image'], data['IR1'] = zip(*data['IR1'].apply(load_and_preprocess_image))\n",
    "\n",
    "data = data.dropna(subset=['image'])\n",
    "\n",
    "images = tf.stack(list(data['image'].values))\n",
    "labels = data['WMO_WIND'].values.astype(float)\n",
    "\n",
    "filenames = data['IR1'].values\n",
    "\n",
    "dataset_display = tf.data.Dataset.from_tensor_slices((images, labels, filenames))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 10\n",
    "image_samples = dataset_display.take(num_images)\n",
    "\n",
    "for image, label, image_filename in image_samples:\n",
    "    wind_value = label.numpy() \n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Wind Value: {wind_value}\\nFilename: {image_filename}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(train_size).batch(batch_size).prefetch(1)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "k = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "for train_index, val_index in skf.split(images, labels):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((images[train_index], labels[train_index]))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((images[val_index], labels[val_index]))\n",
    "    \n",
    "    train_dataset = train_dataset.shuffle(1000).batch(32)\n",
    "    val_dataset = val_dataset.batch(32)\n",
    "    \n",
    "    data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    "    )\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(train_dataset, epochs=20, verbose=0)\n",
    "    \n",
    "    train_loss, train_accuracy = model.evaluate(train_dataset, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(val_dataset, verbose=0)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "print('Average training loss:', np.mean(train_losses))\n",
    "print('Average training accuracy:', np.mean(train_accuracies))\n",
    "print('Training losses:', train_losses)\n",
    "print('Training accuracies:', train_accuracies)\n",
    "print('Average validation loss:', np.mean(val_losses))\n",
    "print('Average validation accuracy:', np.mean(val_accuracies))\n",
    "print('Validation losses:', val_losses)\n",
    "print('Validation accuracies:', val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Dataset/Dataset.csv\")\n",
    "data.head()\n",
    "\n",
    "features = [\"SEASON\", \"SUBBASIN\", \"ISO_TIME\", \"WMO_WIND\"]\n",
    "#features.append(\"WMO_PRES\")\n",
    "data = data[features]\n",
    "data.head()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "date_series = data[\"ISO_TIME\"]\n",
    "datetime_series = pd.to_datetime(date_series, format=\"%d-%m-%Y %H:%M\")\n",
    "formatted_series = datetime_series.dt.strftime(\"%d%b%Y_%H%M\").str.upper()\n",
    "file_name = \"3DIMG_\" + formatted_series + \"_L1C_ASIA_MER_IR1_V01R00.jpg\"\n",
    "\n",
    "file_name.head()\n",
    "\n",
    "data[\"IR1\"] = file_name\n",
    "\n",
    "data.head()\n",
    "\n",
    "data['WMO_WIND'] = data['WMO_WIND'].replace(' ', 0)\n",
    "data['WMO_WIND'] = pd.to_numeric(data['WMO_WIND'], errors='coerce')\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    try:\n",
    "        image = tf.io.read_file('Dataset/pre-processing/Mean-Shift-Segmentation/' + image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, (256, 256))\n",
    "        image = image / 255.0\n",
    "        return image, image_path\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None, image_path\n",
    "\n",
    "data['image'], data['IR1'] = zip(*data['IR1'].apply(load_and_preprocess_image))\n",
    "\n",
    "data = data.dropna(subset=['image'])\n",
    "\n",
    "images = tf.stack(list(data['image'].values))\n",
    "labels = data['WMO_WIND'].values.astype(float)\n",
    "\n",
    "filenames = data['IR1'].values\n",
    "\n",
    "dataset_display = tf.data.Dataset.from_tensor_slices((images, labels, filenames))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 10\n",
    "image_samples = dataset_display.take(num_images)\n",
    "\n",
    "for image, label, image_filename in image_samples:\n",
    "    wind_value = label.numpy() \n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Wind Value: {wind_value}\\nFilename: {image_filename}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(train_size).batch(batch_size).prefetch(1)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "k = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "for train_index, val_index in skf.split(images, labels):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((images[train_index], labels[train_index]))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((images[val_index], labels[val_index]))\n",
    "    \n",
    "    train_dataset = train_dataset.shuffle(1000).batch(32)\n",
    "    val_dataset = val_dataset.batch(32)\n",
    "    \n",
    "    data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    "    )\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3), kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(32, (3,3), 1, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(train_dataset, epochs=20, verbose=0)\n",
    "    \n",
    "    train_loss, train_accuracy = model.evaluate(train_dataset, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(val_dataset, verbose=0)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "print('Average training loss:', np.mean(train_losses))\n",
    "print('Average training accuracy:', np.mean(train_accuracies))\n",
    "print('Training losses:', train_losses)\n",
    "print('Training accuracies:', train_accuracies)\n",
    "print('Average validation loss:', np.mean(val_losses))\n",
    "print('Average validation accuracy:', np.mean(val_accuracies))\n",
    "print('Validation losses:', val_losses)\n",
    "print('Validation accuracies:', val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Dataset/Dataset.csv\")\n",
    "data.head()\n",
    "\n",
    "features = [\"SEASON\", \"SUBBASIN\", \"ISO_TIME\", \"WMO_WIND\"]\n",
    "#features.append(\"WMO_PRES\")\n",
    "data = data[features]\n",
    "data.head()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "date_series = data[\"ISO_TIME\"]\n",
    "datetime_series = pd.to_datetime(date_series, format=\"%d-%m-%Y %H:%M\")\n",
    "formatted_series = datetime_series.dt.strftime(\"%d%b%Y_%H%M\").str.upper()\n",
    "file_name = \"3DIMG_\" + formatted_series + \"_L1C_ASIA_MER_IR1_V01R00.jpg\"\n",
    "\n",
    "file_name.head()\n",
    "\n",
    "data[\"IR1\"] = file_name\n",
    "\n",
    "data.head()\n",
    "\n",
    "data['WMO_WIND'] = data['WMO_WIND'].replace(' ', 0)\n",
    "data['WMO_WIND'] = pd.to_numeric(data['WMO_WIND'], errors='coerce')\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    try:\n",
    "        image = tf.io.read_file('Dataset/images/' + image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, (256, 256))\n",
    "        image = image / 255.0\n",
    "        return image, image_path\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return None, image_path\n",
    "\n",
    "data['image'], data['IR1'] = zip(*data['IR1'].apply(load_and_preprocess_image))\n",
    "\n",
    "data = data.dropna(subset=['image'])\n",
    "\n",
    "images = tf.stack(list(data['image'].values))\n",
    "labels = data['WMO_WIND'].values.astype(float)\n",
    "\n",
    "filenames = data['IR1'].values\n",
    "\n",
    "dataset_display = tf.data.Dataset.from_tensor_slices((images, labels, filenames))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = 10\n",
    "image_samples = dataset_display.take(num_images)\n",
    "\n",
    "for image, label, image_filename in image_samples:\n",
    "    wind_value = label.numpy() \n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Wind Value: {wind_value}\\nFilename: {image_filename}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(train_size).batch(batch_size).prefetch(1)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "k = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "for train_index, val_index in skf.split(images, labels):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((images[train_index], labels[train_index]))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((images[val_index], labels[val_index]))\n",
    "    \n",
    "    train_dataset = train_dataset.shuffle(1000).batch(32)\n",
    "    val_dataset = val_dataset.batch(32)\n",
    "    \n",
    "    data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images within the range (-20, 20) degrees\n",
    "    width_shift_range=0.1,  # Randomly shift the width of images by 0-10% of the total width\n",
    "    height_shift_range=0.1,  # Randomly shift the height of images by 0-10% of the total height\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    zoom_range=0.1  # Randomly zoom images by 0-10%\n",
    "    )\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(train_dataset, epochs=20, verbose=0)\n",
    "    \n",
    "    train_loss, train_accuracy = model.evaluate(train_dataset, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(val_dataset, verbose=0)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "print('Average training loss:', np.mean(train_losses))\n",
    "print('Average training accuracy:', np.mean(train_accuracies))\n",
    "print('Training losses:', train_losses)\n",
    "print('Training accuracies:', train_accuracies)\n",
    "print('Average validation loss:', np.mean(val_losses))\n",
    "print('Average validation accuracy:', np.mean(val_accuracies))\n",
    "print('Validation losses:', val_losses)\n",
    "print('Validation accuracies:', val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
